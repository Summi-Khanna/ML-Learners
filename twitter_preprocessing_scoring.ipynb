{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44539b7f-46ed-424f-a1ab-34ae99d93dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rupika/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rupika/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rupika/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/rupika/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from pre_processing import clean\n",
    "from pre_processing import token_stop_pos\n",
    "from pre_processing import lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aed08ca-dcd9-4bcc-b536-300786c160dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lemma of a word/ POS_data\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188f60eb-7c96-4b29-bd28-992cea5fa4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns Vader Sentiment(compound, pos, neu, neg) Scores given the sentence.\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def get_vaderSentimentScores(title):\n",
    "    vs = analyzer.polarity_scores(title) \n",
    "    return vs['compound'], vs['pos'], vs['neu'], vs['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf5b7af0-2002-4b69-bb65-e60272e01d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new DataFrame with columns 'tweet_id','Vader Sentiment Score', 'pos', 'neu', 'neg' given a Dataframe with lemma words with tweet_id\n",
    "def vadersentimentanalysis(df):\n",
    "    vs_scores = []\n",
    "    for index, row in df.iterrows():\n",
    "        lemma = row['Lemma']\n",
    "        tweet_id = row['tweet_id']\n",
    "        result = [tweet_id]\n",
    "        compound, pos, neu, neg  = get_vaderSentimentScores(lemma)\n",
    "        result.append(compound)\n",
    "        result.append(pos)\n",
    "        result.append(neu)\n",
    "        result.append(neg)\n",
    "        vs_scores.append(result)\n",
    "    score_df = pd.DataFrame(vs_scores, columns = ['tweet_id','Vader Sentiment Score', 'pos', 'neu', 'neg'])\n",
    "    return score_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ed3469-bbeb-4454-a1e4-bcb3152c5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Global variables\n",
    "total_rows = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8579f72-6da6-41ab-871f-6949023cd484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set Global Variable total_rows\n",
    "def set_total_rows(rows):\n",
    "    global total_rows\n",
    "    total_rows = rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e57324-cfae-4d49-ab1e-5fb35096975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fet Global Variable total_rows\n",
    "def get_total_rows():\n",
    "    return total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d52dc7-b4fd-40c6-a8ae-a71a5075d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get indexe range given number of rows by splitting them into rnage of 100000\n",
    "def get_index_range():\n",
    "    total_rows = get_total_rows()\n",
    "    indexes = list(range(0,total_rows,100000))\n",
    "    indexes.append(total_rows)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db379a43-1992-49dc-8846-9babf0fd3e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550441509175443456</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>VisualStockRSRC</td>\n",
       "      <td>1420070457</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550441672312512512</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>KeralaGuy77</td>\n",
       "      <td>1420070496</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550441732014223360</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>DozenStocks</td>\n",
       "      <td>1420070510</td>\n",
       "      <td>S&amp;P100 #Stocks Performance $HD $LOW $SBUX $TGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550442977802207232</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>ShowDreamCar</td>\n",
       "      <td>1420070807</td>\n",
       "      <td>$GM $TSLA: Volkswagen Pushes 2014 Record Recal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550443807834402816</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>i_Know_First</td>\n",
       "      <td>1420071005</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id ticker_symbol        date           writer   post_date  \\\n",
       "0  550441509175443456          AAPL  2014-12-31  VisualStockRSRC  1420070457   \n",
       "1  550441672312512512          AAPL  2014-12-31      KeralaGuy77  1420070496   \n",
       "2  550441732014223360          AMZN  2014-12-31      DozenStocks  1420070510   \n",
       "3  550442977802207232          TSLA  2014-12-31     ShowDreamCar  1420070807   \n",
       "4  550443807834402816          AAPL  2014-12-31     i_Know_First  1420071005   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
       "1  Insanity of today weirdo massive selling. $aap...            0   \n",
       "2  S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
       "3  $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
       "4  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "\n",
       "   retweet_num  like_num  \n",
       "0            0         1  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         1  \n",
       "4            0         1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_tweets = pd.read_csv('./data/stocks_tweet.csv')\n",
    "stock_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851e48aa-963e-4bc5-adde-e4638d5450c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550441509175443456</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>VisualStockRSRC</td>\n",
       "      <td>1420070457</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lx made on AAPL Check it out http profit ly Mn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550441672312512512</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>KeralaGuy77</td>\n",
       "      <td>1420070496</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Insanity of today weirdo massive selling aapl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550441732014223360</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>DozenStocks</td>\n",
       "      <td>1420070510</td>\n",
       "      <td>S&amp;P100 #Stocks Performance $HD $LOW $SBUX $TGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S P Stocks Performance HD LOW SBUX TGT DVN IBM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550442977802207232</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>ShowDreamCar</td>\n",
       "      <td>1420070807</td>\n",
       "      <td>$GM $TSLA: Volkswagen Pushes 2014 Record Recal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GM TSLA Volkswagen Pushes Record Recall Tally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550443807834402816</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>i_Know_First</td>\n",
       "      <td>1420071005</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Swing Trading Up To Return In Days http ow ly ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id ticker_symbol        date           writer   post_date  \\\n",
       "0  550441509175443456          AAPL  2014-12-31  VisualStockRSRC  1420070457   \n",
       "1  550441672312512512          AAPL  2014-12-31      KeralaGuy77  1420070496   \n",
       "2  550441732014223360          AMZN  2014-12-31      DozenStocks  1420070510   \n",
       "3  550442977802207232          TSLA  2014-12-31     ShowDreamCar  1420070807   \n",
       "4  550443807834402816          AAPL  2014-12-31     i_Know_First  1420071005   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
       "1  Insanity of today weirdo massive selling. $aap...            0   \n",
       "2  S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
       "3  $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
       "4  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "\n",
       "   retweet_num  like_num                                      cleaned_tweet  \n",
       "0            0         1  lx made on AAPL Check it out http profit ly Mn...  \n",
       "1            0         0  Insanity of today weirdo massive selling aapl ...  \n",
       "2            0         0  S P Stocks Performance HD LOW SBUX TGT DVN IBM...  \n",
       "3            0         1   GM TSLA Volkswagen Pushes Record Recall Tally...  \n",
       "4            0         1  Swing Trading Up To Return In Days http ow ly ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleans the tweets\n",
    "stock_tweets['cleaned_tweet'] = stock_tweets['body'].apply(clean)\n",
    "stock_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b528c87-a1e0-47f2-8917-7a82ccfce4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL     1425013\n",
       "TSLA     1096868\n",
       "AMZN      718715\n",
       "GOOG      392569\n",
       "MSFT      375711\n",
       "GOOGL     327569\n",
       "Name: ticker_symbol, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_tweets['ticker_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "467013c2-6a5f-4d95-ba42-62aa7e6cb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the stock_tweets is huge file to make preprocessing easy\n",
    "# we are splitting them into smaller files of size 100000 rows for a given company\n",
    "\n",
    "def create_company_tweet_files(company_name):\n",
    "    display(print('Inside the create_company_tweet_files'))\n",
    "    display(print(f'Reading {company_name} tweets from stock_tweets'))\n",
    "    company_tweet = stock_tweets.loc[stock_tweets['ticker_symbol'] == company_name]\n",
    "    set_total_rows(company_tweet.shape[0])\n",
    "    total_rows = get_total_rows()\n",
    "    display(print(f'Total {company_name} tweets size is : {total_rows}'))\n",
    "    indexes = get_index_range()\n",
    "    display(print(f'Splitting {company_name} tweets as follows'))\n",
    "    indexes\n",
    "    for i in range(len(indexes)-1):\n",
    "        display(print(f'inside the range {i} in {indexes[i]} - {indexes[i+1]}'))\n",
    "        file_name = './data/' + company_name + '_tweet_' + str(i) + '.csv'\n",
    "        company_tweet.iloc[indexes[i]:indexes[i+1]].to_csv(file_name)\n",
    "        display(print(f'created filename : {file_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98536d96-5576-4d67-96d5-427c5ec4676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the company_name for which the score files need to be created\n",
    "# For our analysis we used 'AMZN' and 'TSLA'\n",
    "company_name = 'AMZN'\n",
    "# company_name = 'TSLA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ce30b5-ec4c-450c-adfd-03f5edd46a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside the create_company_tweet_files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading AMZN tweets from stock_tweets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total AMZN tweets size is : 718715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting AMZN tweets as follows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside the range 0 in 0 - 100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created filename : ./data/AMZN_tweet_0.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside the range 1 in 100000 - 200000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created filename : ./data/AMZN_tweet_1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside the range 2 in 200000 - 300000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created filename : ./data/AMZN_tweet_2.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside the range 3 in 300000 - 400000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created filename : ./data/AMZN_tweet_3.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside the range 4 in 400000 - 500000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created filename : ./data/AMZN_tweet_4.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside the range 5 in 500000 - 600000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created filename : ./data/AMZN_tweet_5.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside the range 6 in 600000 - 700000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created filename : ./data/AMZN_tweet_6.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside the range 7 in 700000 - 718715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created filename : ./data/AMZN_tweet_7.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_company_tweet_files(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed0542b-041a-4dfc-ad9e-cbf99b732a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718715"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49c4e810-7440-4eb5-b907-34b00ba421b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = './data/'+ company_name\n",
    "os.makedirs(folder_name, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa082eda-6e06-402f-81e6-39e61f126dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718715"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = get_total_rows()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110b06c-3e9c-4d80-b215-23eae3e5241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 100000, 200000, 300000, 400000, 500000, 600000, 700000, 718715]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = get_index_range()\n",
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a828fb-0b26-41a8-9790-3c88cff89d22",
   "metadata": {},
   "source": [
    "In this section we do the following : \n",
    " 1) Read the smaller file\n",
    " 2) Call `token_stop_pos` on `cleaned_tweet` which tokenizes, removes stop words and gives POS(Parts of Speech).\n",
    " 3) Call `lemmatize` on `POS tagged` which gives lemma of the column.\n",
    " 4) Call `vadersentimentanalysis` which returns vader scores for the `Lemma`\n",
    " 5) Writing the final DataFrame into a csv file to its designated folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44eae572-355f-492b-9638-e760d67cec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading filename : ./data/AMZN_tweet_0.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file created : ./data/AMZN/final_AMZN_tweet_0.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading filename : ./data/AMZN_tweet_1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file created : ./data/AMZN/final_AMZN_tweet_1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading filename : ./data/AMZN_tweet_2.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file created : ./data/AMZN/final_AMZN_tweet_2.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading filename : ./data/AMZN_tweet_3.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file created : ./data/AMZN/final_AMZN_tweet_3.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading filename : ./data/AMZN_tweet_4.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file created : ./data/AMZN/final_AMZN_tweet_4.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading filename : ./data/AMZN_tweet_5.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file created : ./data/AMZN/final_AMZN_tweet_5.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading filename : ./data/AMZN_tweet_6.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file created : ./data/AMZN/final_AMZN_tweet_6.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading filename : ./data/AMZN_tweet_7.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file created : ./data/AMZN/final_AMZN_tweet_7.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i in range(len(indexes)-1):\n",
    "    file_name = './data/' + company_name + '_tweet_' + str(i) + '.csv'\n",
    "    display(print(f'Reading filename : {file_name}'))\n",
    "    company_df = pd.read_csv(file_name)\n",
    "    company_df = company_df.drop(columns=['Unnamed: 0'])\n",
    "    display(print(f'POS tagging started'))\n",
    "    company_df['POS tagged'] = company_df['cleaned_tweet'].apply(token_stop_pos)\n",
    "    display(print(f'POS tagging ended'))\n",
    "    display(print(f'Lemma started'))\n",
    "    company_df['Lemma'] = company_df['POS tagged'].apply(lemmatize)\n",
    "    display(print(f'Lemma ended'))\n",
    "    display(print(f'Sentiment score started'))\n",
    "    t_df = company_df[['tweet_id','Lemma']]\n",
    "    vs_df = vadersentimentanalysis(t_df)\n",
    "    company_df = company_df.set_index('tweet_id').join(vs_df.set_index('tweet_id'))\n",
    "    display(print(f'Sentiment score ended'))\n",
    "    folder_name = './data/'+ company_name\n",
    "    os.makedirs(folder_name, exist_ok = True)\n",
    "    final_file_name = folder_name + '/final_'+company_name+'_tweet_' + str(i) + '.csv'\n",
    "    company_df.to_csv(final_file_name)\n",
    "    display(print(f'Final file created : {final_file_name}'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74176593-5af1-454f-b3b3-73a040e58d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dfs = []\n",
    "file_range = range(len(indexes)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "368a5e85-8031-4f43-aa68-4c72107ea306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d8212-52a0-41fd-9eb7-a2c73996ffc5",
   "metadata": {},
   "source": [
    "Reading the smaller files created above and combining it to single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "885c7d44-8f13-4512-9882-2994b3ee2d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started filename : ./data/AMZN/final_AMZN_tweet_0.csv\n",
      "started filename : ./data/AMZN/final_AMZN_tweet_1.csv\n",
      "started filename : ./data/AMZN/final_AMZN_tweet_2.csv\n",
      "started filename : ./data/AMZN/final_AMZN_tweet_3.csv\n",
      "started filename : ./data/AMZN/final_AMZN_tweet_4.csv\n",
      "started filename : ./data/AMZN/final_AMZN_tweet_5.csv\n",
      "started filename : ./data/AMZN/final_AMZN_tweet_6.csv\n",
      "started filename : ./data/AMZN/final_AMZN_tweet_7.csv\n"
     ]
    }
   ],
   "source": [
    "for i in file_range:\n",
    "    final_file_name = folder_name + '/final_'+company_name+'_tweet_' + str(i) + '.csv'\n",
    "    print(f'started filename : {final_file_name}')\n",
    "    df = pd.read_csv(final_file_name , infer_datetime_format=True, parse_dates=True)\n",
    "    small_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "894a4728-64fa-4cd3-a910-315a95ef598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_company_df = pd.concat(small_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef096100-b518-4f1d-af7a-9378b30f9bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                   int64\n",
       "ticker_symbol             object\n",
       "date                      object\n",
       "writer                    object\n",
       "post_date                  int64\n",
       "body                      object\n",
       "comment_num                int64\n",
       "retweet_num                int64\n",
       "like_num                   int64\n",
       "cleaned_tweet             object\n",
       "POS tagged                object\n",
       "Lemma                     object\n",
       "Vader Sentiment Score    float64\n",
       "pos                      float64\n",
       "neu                      float64\n",
       "neg                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_company_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd5e5514-7d8f-4172-81f0-7114528f05af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                          int64\n",
       "ticker_symbol                    object\n",
       "date                     datetime64[ns]\n",
       "writer                           object\n",
       "post_date                         int64\n",
       "body                             object\n",
       "comment_num                       int64\n",
       "retweet_num                       int64\n",
       "like_num                          int64\n",
       "cleaned_tweet                    object\n",
       "POS tagged                       object\n",
       "Lemma                            object\n",
       "Vader Sentiment Score           float64\n",
       "pos                             float64\n",
       "neu                             float64\n",
       "neg                             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_company_df['date'] = pd.to_datetime(final_company_df['date'])\n",
    "final_company_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510d936-a920-46eb-89d2-52795e1fce88",
   "metadata": {},
   "source": [
    "Grouping the tweets by Date and taking mean as aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17f03210-2a13-449d-a693-6e12e95116e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_company_tw_df = final_company_df[['date','Vader Sentiment Score','pos','neu','neg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f08e2572-101d-4c7d-bc63-76b94dfde569",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_company_tw_df = final_company_tw_df.groupby([final_company_tw_df['date'].dt.date]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "495349d6-fb79-4c03-9116-01ac63ae0723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1827, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_company_tw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57170215-b942-4a73-93ad-87924e9b15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_name = company_name + '_TWT_VaderSentimentScore'\n",
    "col2_name = company_name + '_TWT_pos'\n",
    "col3_name = company_name + '_TWT_neu'\n",
    "col4_name = company_name + '_TWT_neg'\n",
    "\n",
    "final_company_tw_df = final_company_tw_df.set_axis(['col1_name', 'col2_name', 'col3_name', 'col4_name'], axis=1, inplace=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d73a22-f315-4542-a880-bf493f7c0fda",
   "metadata": {},
   "source": [
    "Writing the final grpuped DataFrame to a final `Twitter_Scores.csv` file for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ac33169-aaba-40c7-a2b5-1b91af096bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_company_tw_file_name = './data/'+ company_name + '_Twitter_Scores.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38e5b9eb-337a-4db2-9fab-401c83a311cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_company_tw_df.to_csv(final_company_tw_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2531aa1-be65-413d-9377-6047613676ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
